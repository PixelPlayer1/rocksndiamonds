{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import spline\n",
    "\n",
    "import itertools\n",
    "import copy\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk data concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../training_data/\"\n",
    "data_levelsets = [\"train1\", \"train2\", \"train3\", \"train4\"]\n",
    "data_levels = range(1, 990+1)\n",
    "observation_ext = \"observation.zip\"\n",
    "feature_ext = \"feature.zip\"\n",
    "\n",
    "def _addRowAndCol(feature_tensor):\n",
    "    # 3xnxn -> 3x(n+1)x(n+1)\n",
    "    n = feature_tensor.size()[1]\n",
    "    channels = []\n",
    "    new_col = torch.zeros(n, 1)\n",
    "    new_row = torch.zeros(1, n+1)\n",
    "    for channel in feature_tensor:\n",
    "        output_tensor = torch.cat((channel, new_col), dim=1)\n",
    "        output_tensor = torch.cat((output_tensor, new_row), dim=0)\n",
    "        channels.append(output_tensor)\n",
    "    return torch.stack(channels)\n",
    "    \n",
    "\n",
    "def dataGatherOnlyObservedSolutions():\n",
    "    features = []\n",
    "    observations = []\n",
    "    for levelset, levelnum in itertools.product(*[data_levelsets, data_levels]):\n",
    "        level_feature_path = '{}{}_{}_{}'.format(data_path, levelset, levelnum, feature_ext)\n",
    "        level_observation_path = '{}{}_{}_{}'.format(data_path, levelset, levelnum, observation_ext)\n",
    "        \n",
    "        level_features = torch.load(level_feature_path)\n",
    "        level_observations = torch.load(level_observation_path)\n",
    "        \n",
    "        for feat, obs in zip(level_features, level_observations):\n",
    "            if obs[1] == 1:\n",
    "#                 features.append(feat.clone())\n",
    "                features.append(_addRowAndCol(feat.clone()))\n",
    "                observations.append(torch.tensor([obs[0].clone()], dtype=torch.float32))\n",
    "        del level_features\n",
    "        del level_observations\n",
    "                \n",
    "    return torch.stack(features), torch.stack(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Standardizing\n",
    "- Features are standardized to mean 0 and std 1\n",
    "- Observations are normalzed to range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessFeatures(features):\n",
    "    # features is shape [N, 2, 39, 39]\n",
    "    # permute to channel is top most axis\n",
    "    temp_feats = features.clone().permute(*[i for i in range(1, len(features.shape))], 0).contiguous()\n",
    "    # Calculate mean/std for standardization\n",
    "    mean = temp_feats.view(2, -1).mean(dim=1)\n",
    "    std = temp_feats.view(2, -1).std(dim=1)\n",
    "    # Normalize original features\n",
    "    for f in features:\n",
    "        for i, (mu, sigma) in enumerate(zip(mean.tolist(), std.tolist())):\n",
    "            f[i].sub_(mu)\n",
    "            f[i].div_(sigma)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def preprocessObservations(observations):\n",
    "    return torch.log(observations)\n",
    "#     return observations / max(observations)\n",
    "#     return torch.log(observations) / max(torch.log(observations))\n",
    "\n",
    "def getDataLoader(features, observations, batch_size=64):\n",
    "    data = [(feat, obs) for feat, obs in zip(features, observations)]\n",
    "    return torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisNetCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ks1 = 3\n",
    "        ks2 = 3\n",
    "        ks3 = 1\n",
    "        \n",
    "        conv1_depth = 16\n",
    "        conv2_depth = 32\n",
    "        \n",
    "        # convolution layers\n",
    "        self.conv1 = nn.Conv2d(2, conv1_depth, kernel_size=ks1, stride=1, padding=1)\n",
    "        torch.nn.init.xavier_uniform_(self.conv1.weight)\n",
    "        self.conv2 = nn.Conv2d(conv1_depth, conv2_depth, kernel_size=ks2, stride=1, padding=1)\n",
    "        torch.nn.init.xavier_uniform_(self.conv2.weight)\n",
    "        self.conv3 = nn.Conv2d(conv2_depth, 1, kernel_size=ks3, stride=1, padding=0)\n",
    "        torch.nn.init.xavier_uniform_(self.conv3.weight)\n",
    "        \n",
    "        # pooling\n",
    "        self.maxPool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout2d(0.2)\n",
    "        self.dropout2 = nn.Dropout2d(0.3)\n",
    "#         self.avgPool = nn.AveragePool2d(2, 2)\n",
    "        # subsampling\n",
    "        \n",
    "        # FC\n",
    "        self.fc1 = nn.Linear(40*40, 64)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(F.relu(self.fc2(x)))\n",
    "        x = self.dropout2(F.relu(self.fc3(x)))\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self, fc1_size=64, fc2_size=32):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout2d(0.0)\n",
    "        \n",
    "        self.fc1 = nn.Linear(40*40*2, fc1_size)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(fc1_size, fc2_size)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        self.fc3 = nn.Linear(fc2_size, 1)\n",
    "        torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options = namedtuple('Options', ['n_epochs', 'batch_size', 'start_rate', 'end_rate', 'clip_gradient_norm', \n",
    "#                                  'loss_fn', 'verbose']\n",
    "#                     )\n",
    "# default_options = Options(n_epochs=100, batch_size=64, start_rate=1e-3, end_rate=1e-5, \n",
    "#                           clip_gradient_norm=1e-2, loss_fn=nn.MSELoss(), verbose=False\n",
    "#                          )\n",
    "default_options = {'n_epochs' : 100, 'batch_size' : 64, 'start_rate' : 1e-3, 'end_rate' : 1e-5, \n",
    "                          'clip_gradient_norm' : 1e-2, 'loss_fn' : nn.MSELoss(), 'verbose' : False\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(features, observations, options=default_options):\n",
    "def train(model, device, train_loader, validation_loader, options=default_options):\n",
    "    \n",
    "    # Set device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Get training attributes from options\n",
    "    loss_fn = options['loss_fn']\n",
    "    start_rate = options['start_rate']\n",
    "    end_rate = options['end_rate']\n",
    "    n_epochs = options['n_epochs']\n",
    "    clip_gradient_norm = options['clip_gradient_norm']\n",
    "#     loss_fn = nn.NLLLoss()\n",
    "    \n",
    "    # Optimizers\n",
    "    # - learning rate start 1e-3 to end 1e-5 [done]\n",
    "    # - gradient clipping [done]\n",
    "    # - tanh activation function\n",
    "    # - SGD [done]\n",
    "    # - batch normalization (as a layer)\n",
    "    # - L2 regularization of 1e-4\n",
    "    decay_rate = np.exp(np.log(end_rate / start_rate) / n_epochs)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=start_rate)\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=start_rate, weight_decay=0.01)\n",
    "    lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decay_rate)\n",
    "    \n",
    "    loss_values = []\n",
    "    for epoch in range(n_epochs):\n",
    "        training_loss = 0.0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            # get the inputs; data is a list of [features, runtime]\n",
    "            inputs, rts = data\n",
    "            inputs, rts = inputs.to(device), rts.to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Propogate input to model and calculate loss\n",
    "            batch_size = inputs.shape[0]\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, rts)\n",
    "            \n",
    "            # Add l2 loss\n",
    "            \n",
    "            # Clip the gradients\n",
    "            if clip_gradient_norm != None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_gradient_norm)\n",
    "            \n",
    "            # Propogate loss backwards and step optimizer\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "#             running_loss =+ loss.item() * inputs.size(0)\n",
    "            training_loss += loss.item()\n",
    "            \n",
    "        # Get validation loss\n",
    "        validation_loss = 0.0\n",
    "        for i, data in enumerate(validation_loader):\n",
    "            inputs, rts = data\n",
    "            inputs, rts = inputs.to(device), rts.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, rts)\n",
    "            validation_loss += loss.item()\n",
    "            \n",
    "        # Store training and validation loss\n",
    "        loss_values.append((training_loss / len(train_loader), validation_loss / len(validation_loader)))\n",
    "        if options['verbose'] and epoch % 10 == 9: print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss_values[-1][0])))\n",
    "        \n",
    "        # Update learning rate\n",
    "        lr_scheduler.step()\n",
    "    return loss_values, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single set validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(features, observations, model, options=default_options):\n",
    "    # Preprocess input\n",
    "    features = preprocessFeatures(features)\n",
    "    observations = preprocessObservations(observations)\n",
    "    \n",
    "    # Create dataloader\n",
    "    test_loader = getDataLoader(features, observations, options.batch_size)\n",
    "    \n",
    "    # Don't need to backprop during testing\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "             # get the inputs; data is a list of [features, runtime]\n",
    "            inputs, rts = data\n",
    "            inputs, rts = inputs.to(device), rts.to(device)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfoldValidation(features, observations, options, model):\n",
    "    # Get training attributes from options\n",
    "    batch_size = options['batch_size']\n",
    "    loss_fn = options['loss_fn']\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    test_losses = []\n",
    "    for training_idx, test_idx in kf.split(features):\n",
    "        # Split data\n",
    "        train_features, test_features = features[training_idx,:], features[test_idx,:]\n",
    "        train_observations, test_observations = observations[training_idx,:], observations[test_idx,:]\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_loader = getDataLoader(train_features, train_observations, batch_size)\n",
    "        test_loader = getDataLoader(test_features, test_observations, batch_size)\n",
    "        \n",
    "        # Train model\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        loss_values, model = train(model, device, train_loader, test_loader, options)\n",
    "        \n",
    "        # Test \n",
    "        # Don't need to backprop during testing\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                inputs, rts = data\n",
    "                inputs, rts = inputs.to(device), rts.to(device)  \n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, rts)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "        # Save avg loss\n",
    "        test_losses.append(test_loss / len(test_loader))\n",
    "        \n",
    "    # Average losses\n",
    "    return np.mean(test_losses)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util and Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN Model Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-d631bea7432e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Run K-fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfoldValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-db6f0fa76695>\u001b[0m in \u001b[0;36mkfoldValidation\u001b[0;34m(features, observations, options, model)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-104-3f14f2000fb2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, validation_loader, options)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# Propogate loss backwards and step optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m#             running_loss =+ loss.item() * inputs.size(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "features = torch.load('train_nokey_only_solution_feats.pt')\n",
    "observations = torch.load('train_nokey_only_solution_obs.pt')\n",
    "\n",
    "# Training base options\n",
    "base_options = copy.deepcopy(default_options)\n",
    "base_options['n_epochs'] = 400\n",
    "base_options['batch_size'] = 16\n",
    "base_options['start_rate'] = 1e-4\n",
    "base_options['end_rate'] = 1e-6\n",
    "\n",
    "\n",
    "\n",
    "# Gridsearch options\n",
    "param_grid = {'batch_size': [16, 32, 64], \n",
    "              'l_rates' : [(1e-3, 1e-4), (1e-3, 1e-5), (1e-3, 1e-6), (1e-3, 1e-7),\n",
    "                           (1e-4, 1e-5), (1e-4, 1e-6), (1e-4, 1e-7), (1e-5, 1e-6),\n",
    "                           (1e-5, 1e-7), (1e-6, 1e-7)],\n",
    "              'fc1': [16, 32, 64, 128],\n",
    "              'fc2': [16, 32, 64, 128],\n",
    "             }\n",
    "\n",
    "# preprocess\n",
    "features = preprocessFeatures(features)\n",
    "observations = preprocessObservations(observations)\n",
    "\n",
    "# Run gridsearch\n",
    "results = []\n",
    "for i, params in enumerate(ParameterGrid(param_grid)):\n",
    "    if i % 10 == 9: print(i+1)\n",
    "    current_options = copy.deepcopy(base_options)\n",
    "    # Set params\n",
    "    current_options['batch_size'] = params['batch_size']\n",
    "    current_options['start_rate'] = params['l_rates'][0]\n",
    "    current_options['end_rate'] = params['l_rates'][1]\n",
    "    model = FCN(params['fc1'], params['fc2'])\n",
    "    \n",
    "    # Run K-fold\n",
    "    results.append((kfoldValidation(features, observations, current_options, model), current_options))\n",
    "    \n",
    "# Print results\n",
    "print(sorted(results, key=lambda x : x[0], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single K-fold test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9618216724693776, {'n_epochs': 400, 'batch_size': 16, 'start_rate': 0.0001, 'end_rate': 1e-06, 'clip_gradient_norm': 0.01, 'loss_fn': MSELoss(), 'verbose': False, 'fcn_i': (128, 32)})\n",
      "(0.9662183678150175, {'n_epochs': 400, 'batch_size': 16, 'start_rate': 0.0001, 'end_rate': 1e-06, 'clip_gradient_norm': 0.01, 'loss_fn': MSELoss(), 'verbose': False, 'fcn_i': (128, 64)})\n",
      "(1.009751491546631, {'n_epochs': 400, 'batch_size': 16, 'start_rate': 0.0001, 'end_rate': 1e-06, 'clip_gradient_norm': 0.01, 'loss_fn': MSELoss(), 'verbose': False, 'fcn_i': (128, 128)})\n",
      "(1.024035993695259, {'n_epochs': 400, 'batch_size': 16, 'start_rate': 0.0001, 'end_rate': 1e-06, 'clip_gradient_norm': 0.01, 'loss_fn': MSELoss(), 'verbose': False, 'fcn_i': (64, 32)})\n",
      "(1.1157941100001334, {'n_epochs': 400, 'batch_size': 16, 'start_rate': 0.0001, 'end_rate': 1e-06, 'clip_gradient_norm': 0.01, 'loss_fn': MSELoss(), 'verbose': False, 'fcn_i': (32, 32)})\n",
      "(1.1432155785560607, {'n_epochs': 400, 'batch_size': 16, 'start_rate': 0.0001, 'end_rate': 1e-06, 'clip_gradient_norm': 0.01, 'loss_fn': MSELoss(), 'verbose': False, 'fcn_i': (64, 64)})\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "features = torch.load('train_nokey_only_solution_feats.pt')\n",
    "observations = torch.load('train_nokey_only_solution_obs.pt')\n",
    "\n",
    "# Training base options\n",
    "base_options = copy.deepcopy(default_options)\n",
    "base_options['n_epochs'] = 400\n",
    "base_options['batch_size'] = 16\n",
    "base_options['start_rate'] = 1e-4\n",
    "base_options['end_rate'] = 1e-6\n",
    "\n",
    "\n",
    "\n",
    "# Gridsearch options\n",
    "param_grid = {'fcn_i' : [(128, 128), (128, 64), (128, 32), (64, 64),\n",
    "                           (64, 32), (32, 32)]\n",
    "             }\n",
    "\n",
    "# preprocess\n",
    "features = preprocessFeatures(features)\n",
    "observations = preprocessObservations(observations)\n",
    "\n",
    "# Run gridsearch\n",
    "results = []\n",
    "for i, params in enumerate(ParameterGrid(param_grid)):\n",
    "    current_options = copy.deepcopy(base_options)\n",
    "    current_options['fcn_i'] = params['fcn_i']\n",
    "    # Set params\n",
    "#     current_options['batch_size'] = params['batch_size']\n",
    "#     current_options['start_rate'] = params['l_rates'][0]\n",
    "#     current_options['end_rate'] = params['l_rates'][1]\n",
    "    model = FCN(128, 32)\n",
    "    \n",
    "    # Run K-fold\n",
    "    results.append((kfoldValidation(features, observations, current_options, model), current_options))\n",
    "    \n",
    "# Print results\n",
    "for l in sorted(results, key=lambda x : x[0]):\n",
    "    print(l)\n",
    "# print(sorted(results, key=lambda x : x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get data\n",
    "features = torch.load('train_nokey_only_solution_feats.pt')\n",
    "observations = torch.load('train_nokey_only_solution_obs.pt')\n",
    "\n",
    "# Training options\n",
    "# options = Options(n_epochs=400, batch_size=32, start_rate=1e-3, end_rate=1e-5, clip_gradient_norm=None, verbose=True)\n",
    "# Training base options\n",
    "base_options = copy.deepcopy(default_options)\n",
    "base_options['n_epochs'] = 400\n",
    "base_options['batch_size'] = 16\n",
    "base_options['start_rate'] = 1e-4\n",
    "base_options['end_rate'] = 1e-6\n",
    "\n",
    "# preprocess\n",
    "features = preprocessFeatures(features)\n",
    "observations = preprocessObservations(observations)\n",
    "\n",
    "# Split into train/test\n",
    "indices = np.random.permutation(features.shape[0])\n",
    "training_idx, validation_idx = indices[:80], indices[80:]\n",
    "train_features, validation_features = features[training_idx,:], features[validation_idx,:]\n",
    "train_observations, validation_observations = observations[training_idx,:], observations[validation_idx,:]\n",
    "\n",
    "# device and model\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = DisNetCNN()\n",
    "# model = FCN(128, 32)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = getDataLoader(train_features, train_observations, base_options['batch_size'])\n",
    "validation_loader = getDataLoader(validation_features, validation_observations,  base_options['batch_size'])\n",
    "\n",
    "loss_values, model = train(model, device, train_loader, validation_loader, base_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f068d9003c8>]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(loss_values)\n",
    "window_size = 10\n",
    "plt.plot(smooth([l[0] for l in loss_values], window_size)[window_size:-window_size], 'g')\n",
    "plt.plot(smooth([l[1] for l in loss_values], window_size)[window_size:-window_size], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.]], device='cuda:0', grad_fn=<FeatureDropoutBackward>)\n",
      "tensor([[3.3673]])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "index = 1208\n",
    "f = preprocessFeatures(feats)[index:index+1].to(device)\n",
    "o = preprocessObservations(obs)[index:index+1]\n",
    "print(model(f))\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-c339a1b77006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-dd353fc89653>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_flat_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "summary(model, (2, 40, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# feats, obs = dataGatherOnlyObservedSolutions()\n",
    "# torch.save(feats, 'train_nokey_only_solution_feats.pt')\n",
    "# torch.save(obs, 'train_nokey_only_solution_obs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3960, 2, 40, 40])\n",
      "torch.Size([3960, 1])\n"
     ]
    }
   ],
   "source": [
    "feats = torch.load('train_nokey_only_solution_feats.pt')\n",
    "obs = torch.load('train_nokey_only_solution_obs.pt')\n",
    "print(feats.shape)\n",
    "print(obs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2014, 0.8822, 0.1140, 0.8369],\n",
       "          [0.2918, 0.7020, 0.7541, 0.3556],\n",
       "          [0.5786, 0.8386, 0.7378, 0.5152],\n",
       "          [0.9454, 0.2910, 0.9145, 0.5884]],\n",
       "\n",
       "         [[0.7923, 0.7909, 0.1098, 0.3195],\n",
       "          [0.4803, 0.4007, 0.6035, 0.5743],\n",
       "          [0.0171, 0.2761, 0.9388, 0.6652],\n",
       "          [0.5459, 0.6032, 0.4494, 0.3658]]],\n",
       "\n",
       "\n",
       "        [[[0.7770, 0.7051, 0.3316, 0.8457],\n",
       "          [0.2978, 0.7117, 0.1090, 0.3297],\n",
       "          [0.6302, 0.1306, 0.3089, 0.6453],\n",
       "          [0.1877, 0.4400, 0.6960, 0.0021]],\n",
       "\n",
       "         [[0.6115, 0.4842, 0.6426, 0.3837],\n",
       "          [0.9901, 0.3421, 0.5447, 0.2467],\n",
       "          [0.8325, 0.7696, 0.2741, 0.2561],\n",
       "          [0.2276, 0.2711, 0.4679, 0.4610]]],\n",
       "\n",
       "\n",
       "        [[[0.3534, 0.6828, 0.2816, 0.1926],\n",
       "          [0.4594, 0.9886, 0.3416, 0.1624],\n",
       "          [0.8285, 0.4373, 0.4972, 0.4604],\n",
       "          [0.5750, 0.9687, 0.7848, 0.4529]],\n",
       "\n",
       "         [[0.0018, 0.5595, 0.9077, 0.3239],\n",
       "          [0.2525, 0.5788, 0.6479, 0.9415],\n",
       "          [0.1342, 0.4970, 0.3793, 0.4762],\n",
       "          [0.9580, 0.2871, 0.8233, 0.8228]]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permTempFeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 4, 3])\n",
      "torch.Size([2, 48])\n",
      "tensor([0.5242, 0.5069])\n",
      "tensor([0.2678, 0.2553])\n",
      "tensor([[[[-1.2056,  1.3370, -1.5320,  1.1678],\n",
      "          [-0.8682,  0.6639,  0.8585, -0.6299],\n",
      "          [ 0.2030,  1.1740,  0.7977, -0.0338],\n",
      "          [ 1.5730, -0.8710,  1.4576,  0.2395]],\n",
      "\n",
      "         [[ 1.1182,  1.1127, -1.5556, -0.7341],\n",
      "          [-0.1041, -0.4160,  0.3785,  0.2643],\n",
      "          [-1.9189, -0.9039,  1.6920,  0.6203],\n",
      "          [ 0.1530,  0.3772, -0.2251, -0.5525]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9440,  0.6756, -0.7194,  1.2005],\n",
      "          [-0.8456,  0.7002, -1.5508, -0.7266],\n",
      "          [ 0.3958, -1.4700, -0.8040,  0.4520],\n",
      "          [-1.2569, -0.3144,  0.6414, -1.9500]],\n",
      "\n",
      "         [[ 0.4101, -0.0887,  0.5317, -0.4824],\n",
      "          [ 1.8931, -0.6453,  0.1483, -1.0191],\n",
      "          [ 1.2756,  1.0292, -0.9119, -0.9826],\n",
      "          [-1.0943, -0.9238, -0.1526, -0.1799]]],\n",
      "\n",
      "\n",
      "        [[[-0.6380,  0.5920, -0.9061, -1.2384],\n",
      "          [-0.2422,  1.7343, -0.6820, -1.3513],\n",
      "          [ 1.1363, -0.3245, -0.1009, -0.2385],\n",
      "          [ 0.1898,  1.6601,  0.9729, -0.2665]],\n",
      "\n",
      "         [[-1.9786,  0.2064,  1.5704, -0.7167],\n",
      "          [-0.9967,  0.2819,  0.5525,  1.7027],\n",
      "          [-1.4601, -0.0385, -0.4999, -0.1201],\n",
      "          [ 1.7673, -0.8612,  1.2397,  1.2376]]]])\n"
     ]
    }
   ],
   "source": [
    "temp1 = preprocessFeatures(permTempFeats)\n",
    "print(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52423125"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1 = [0.2014, 0.8822, 0.1140, 0.8369, 0.2918, 0.7020, 0.7541, 0.3556, 0.5786, 0.8386, 0.7378, 0.5152, 0.9454, 0.2910, 0.9145, 0.5884, \\\n",
    "0.7770, 0.7051, 0.3316, 0.8457, 0.2978, 0.7117, 0.1090, 0.3297, 0.6302, 0.1306, 0.3089, 0.6453, 0.1877, 0.4400, 0.6960, 0.0021, \\\n",
    "0.3534, 0.6828, 0.2816, 0.1926, 0.4594, 0.9886, 0.3416, 0.1624, 0.8285, 0.4373, 0.4972, 0.4604, 0.5750, 0.9687, 0.7848, 0.4529]\n",
    "sum(temp1) / len(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'mean' and 'std'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-02175ba2ce41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'mean' and 'std'"
     ]
    }
   ],
   "source": [
    "transform = transforms.Normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deep-learning)",
   "language": "python",
   "name": "deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
